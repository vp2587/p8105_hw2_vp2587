---
title: "P8105 HW2"
author: "Veerapetch Petchger"
date: "2025-10-01"
output: github_document
---

## Problem 1

#### This problem uses the FiveThirtyEight data; these data were gathered to create the interactive graphic on this page. In particular, we’ll use the data in pols-month.csv, unemployment.csv, and snp.csv. Our goal is to merge these into a single data frame using year and month as keys across datasets.

#### First, clean the data in pols-month.csv. Use separate() to break up the variable mon into integer variables year, month, and day; replace month number with month name; create a president variable taking values gop and dem, and remove prez_dem and prez_gop; and remove the day variable.

```{r setup, include = FALSE}
library(tidyverse)
library(lubridate)
library(readxl)
```

```{r pols-month}
pols_month_df = 
  read.csv("fivethirtyeight_datasets/pols-month.csv", na = c("NA",".","")) %>% 
  janitor::clean_names() %>% 
  separate(mon, into = c("year", "month", "day"), convert = TRUE) %>% 
  mutate(month = factor(month.name[month], levels = month.name, ordered = TRUE),
         president = if_else(prez_gop == 1, "gop", "dem")) %>%
select(-day, -prez_dem, -prez_gop)
```

#### Second, clean the data in snp.csv using a similar process to the above. For consistency across datasets, arrange according to year and month, and organize so that year and month are the leading columns.

```{r snp}
snp_df = 
  read.csv("fivethirtyeight_datasets/snp.csv", na = c("NA",".","")) %>% 
  janitor::clean_names() %>% 
  mutate(
    date = mdy(date),
    year = year(date),
    month = factor(month.name[month(date)], levels = month.name, ordered = TRUE)
  ) %>% 
  arrange(year, month) %>% 
  select(year, month, close)
```

#### Third, tidy the unemployment data so that it can be merged with the previous datasets. This process will involve switching from “wide” to “long” format; ensuring that key variables have the same name; and ensuring that key variables take the same values.

```{r unemployment}
unemployment_df = 
  read.csv("fivethirtyeight_datasets/unemployment.csv", na = c("NA",".","")) %>% 
  janitor::clean_names() %>% 
  pivot_longer(
    col = jan:dec,
    names_to = "month",
    values_to = "unemployment_rate"
  ) %>% 
  mutate(
    month_num = match(str_to_title(month), month.abb),
    month = factor(month.name[month_num], levels = month.name, ordered = TRUE)
  ) %>% 
  select(year, month, unemployment_rate) %>% 
  arrange(year, month)
```

#### Join the datasets by merging snp into pols, and merging unemployment into the result.

```{r joining_datasets}
fte_df =
  pols_month_df %>% 
  left_join(snp_df, by = c("year", "month")) %>% 
  left_join(unemployment_df, by = c("year", "month"))
```

#### Write a short paragraph about these datasets. Explain briefly what each dataset contained, and describe the resulting dataset (e.g. give the dimension, range of years, and names of key variables).

The `pols_month_df` contains information on the number of national politicians that are either democratic or republican on the associated date. The `snp_df` provided the closing values of the S&P stock index at the start of each month, though this was converted to one observation per month per year. The `unemployment_df` provided the unemployment rate of the associated month in a wide format separated by monthly intials. After cleaning and merging, the resulting dataset combines political representation, stock market performance, and unemployment. It has `r nrow(fte_df)` rows and `r ncol(fte_df)` columns spanning over `r max(fte_df$year) - min(fte_df$year)` years.

#### Note: we could have used a date variable as a key instead of creating year and month keys; doing so would help with some kinds of plotting, and be a more accurate representation of the data. Date formats are tricky, though. For more information check out the lubridate package in the tidyverse.

## Problem 2

#### This problem uses the Mr. Trash Wheel dataset, available as an Excel file on the course website.

#### Read and clean the Mr. Trash Wheel sheet:

##### 1) Specify the sheet in the Excel file and to omit non-data entries (rows with notes / figures; columns containing notes) using arguments in read_excel

##### 2) Use reasonable variable names

##### 3) Omit rows that do not include dumpster-specific data

##### 4) Round the number of sports balls to the nearest integer and converts the result to an integer variable (using as.integer)

```{r mr_wheel}
wheel_df = 
  read_excel("202509 Trash Wheel Collection Data.xlsx", 
            sheet = "Mr. Trash Wheel", 
            range = "A2:N710",
            na = c("NA",".","")
            ) %>% 
  janitor::clean_names() %>% 
  select(-contains("note"), 
         -contains("figure"), 
         -contains("source"), 
         -contains("footer"), 
         everything()) %>%  
  filter(!is.na(dumpster)) %>% 
  mutate(
    across(any_of("sports_balls"), ~ as.integer(round(.x))),
    wheel = "Mr. Trash Wheel") %>% 
  relocate(wheel) %>% 
  mutate(year = suppressWarnings(as.integer(year)))
```

#### Use a similar process to import, clean, and organize the data for Professor Trash Wheel and Gwynnda, and combine this with the Mr. Trash Wheel dataset to produce a single tidy dataset. To keep track of which Trash Wheel is which, you may need to add an additional variable to both datasets before combining.

```{r professor}
professor_df = 
  read_excel("202509 Trash Wheel Collection Data.xlsx", 
            sheet = "Professor Trash Wheel", 
            skip = 1,
            na = c("NA",".","")
            ) %>% 
  janitor::clean_names() %>% 
  select(-contains("note"), 
         -contains("figure"), 
         -contains("source"), 
         -contains("footer"), 
         everything()) %>%  
  filter(!is.na(dumpster)) %>% 
  mutate(
    across(any_of("sports_balls"), ~ as.integer(round(.x))),
    wheel = "Professor Trash Wheel"
  ) %>%  
  relocate(wheel) %>% 
  mutate(year = suppressWarnings(as.integer(year)))
```

```{r gwynnda}
gwynnda_df = 
  read_excel("202509 Trash Wheel Collection Data.xlsx", 
            sheet = "Gwynns Falls Trash Wheel",
            na = c("NA",".","")
            ) %>% 
  janitor::clean_names() %>% 
  select(-contains("note"), 
         -contains("figure"), 
         -contains("source"), 
         -contains("footer"), 
         everything()) %>%  
  filter(!is.na(dumpster)) %>% 
  mutate(
    across(any_of("sports_balls"), ~ as.integer(round(.x))),
    wheel = "Gwynns Falls Trash Wheel"
  ) %>%  
  relocate(wheel) %>% 
  mutate(year = suppressWarnings(as.integer(year)))
```

```{r trash_merge}
trash_df = 
  bind_rows(wheel_df, professor_df, gwynnda_df) %>%
  arrange(wheel, year, month, dumpster) %>%
  select(any_of(c("wheel","year","month","date","dumpster")), everything())
```

#### Write a paragraph about these data; you are encouraged to use inline R. Be sure to note the number of observations in the resulting dataset, and give examples of key variables. For available data, what was the total weight of trash collected by Professor Trash Wheel? What was the total number of cigarette butts collected by Gwynnda in June of 2022?

The Trash Wheel dataset combines information from 3 of Baltimore's trash-collecting water wheels, named Mr. Trash Wheel, Professor Trash Wheel, and Gwynnda. After thorough cleaning and merging, the combined dataset contains `r nrow(trash_df)` observations of dumpster collections. Each row represents a collection event for a single dumpster, separated by the `date`, the amount of trash collected (`weight_tons`), with specific insights on the kinds of trash collected. These include `plastic_bags`, `glass_bottles`, and `sports_balls`. Professor Trash Wheel collected a total of `r sum(professor_df$weight_tons)` tons of trash, , while Gywnnda collected `r sum(filter(gwynnda_df, month == "June", year == 2022)$cigarette_butts)` in June 2022.

## Problem 3

#### Home and rental prices have generally increased over the last decade. Zillow, a popular website used to search for homes for sale or rent, is uniquely positioned to provide insights into trends in the real estate market. In response to broad interest, the company releases data for research. In this project, we’ll look at the Zillow Observed Rent Index (ZORI) in New York City between January 2015 and August 2024.

#### NYC is divided into five boroughs. Each of these boroughs is it’s own county, and in some cases the borough name and county name differ; for example, Manhattan is New York County. Moreover, boroughs are divided into neighborhoods. Rental price data provided by Zillow does not include information neighborhoods within boroughs, but can be accessed separately.

#### Both datasets are available here.

#### Create a single, well-organized dataset with all the information contained in these data files. To that end: import, clean, tidy, and otherwise wrangle each of these datasets; check for completeness and correctness across datasets (e.g. by viewing individual datasets and monitoring warning messages); merge to create a single, final dataset; and organize this so that variables and observations are in meaningful orders.

```{r zip_codes}
zip_codes_df =
  read_csv("zillow_data/Zip Codes.csv") %>% 
  janitor::clean_names()
```

```{r zora}
zora_df =
  read_csv("zillow_data/Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv") %>% 
  janitor::clean_names() %>%
  rename(zip_code = region_name)

id_cols <- c("region_id","size_rank","zip_code","region_type","state_name","state","city","metro","county_name")
  
zora_df =
  zora_df %>% 
  pivot_longer(
    cols = -all_of(id_cols),
    names_to  = "date_str",
    values_to = "zori"
  ) %>% 
  mutate(
    date  = ymd(gsub("_", "-", sub("^x", "", date_str))),
    year  = year(date),
    month = factor(month.name[month(date)], levels = month.name, ordered = TRUE),
    zori  = as.double(zori),
    size_rank = suppressWarnings(as.integer(size_rank)),
    zip_code = str_pad(as.character(zip_code), 5, pad = "0")
  ) %>% 
  relocate(zip_code, date, year, month, zori, .before = 1) %>% 
  arrange(zip_code, date) %>% 
  select(-date_str, -state, -region_type)
```

```{r zillow_merge}
zip_codes_df <- zip_codes_df %>%
  mutate(zip_code = as.character(zip_code))

zillow_df <- zora_df %>%
  left_join(zip_codes_df, by = "zip_code") %>%  
  relocate(zip_code, year, month, date, zori) %>%  
  arrange(year, month, zip_code) %>% 
  select(-county_name)
```

#### Briefly describe the resulting tidy dataset. How many total observations exist? How many unique ZIP codes are included, and how many unique neighborhoods?

The resulting dataset is a collection of recordings of the Zillow Observed Rent Index (ZORI) in NYC ZIP codes. Each row represents a ZORI value (`zori`) for a given ZIP on a specific month, primarily identified by the `zip_code` and `date`, amounting to `r nrow(zillow_df)` total observations. Helper columns include `state`, `city`, `metro`, and `neighborhood`. There are `r dplyr::n_distinct(zillow_df$zip_code, na.rm = TRUE)` unique ZIP codes and `r dplyr::n_distinct(zillow_df$neighborhood, na.rm = TRUE)` distinct neighborhoods.

#### Which ZIP codes appear in the ZIP code dataset but not in the Zillow Rental Price dataset? Using a few illustrative examples discuss why these ZIP codes might be excluded from the Zillow dataset.

```{r zip_missing}
zip_lookup <- zip_codes_df %>%
  mutate(zip_code = str_pad(as.character(zip_code), 5, pad = "0")) %>%
  distinct(zip_code, .keep_all = TRUE)

zori_keys <- zillow_df %>%
  transmute(zip_code = str_pad(as.character(zip_code), 5, pad = "0")) %>%
  distinct(zip_code)

zips_missing <- anti_join(zip_lookup, zori_keys, by = "zip_code") %>%
  arrange(across(any_of(c("borough","neighborhood","city","county"))), zip_code)

n_missing <- nrow(zips_missing)
```

There are `r n_missing` ZIP codes from the dataset. Reasons for not being included in `zora_df` include that they may reflect P.O. boxes, non-residential areas, or recently retired or reassigned ZIP codes. In special cases, `11371` and `11430` represent LGA and JFK airports, respectively, while `10048` was the ZIP code of the World Trade Center. Furthermore, `10704` and `11001` correspond to Westchester (Bronx) and Nassau (Queens), respectively, but are outside of NYC proper.

#### Rental prices fluctuated dramatically during the COVID-19 pandemic. For all available ZIP codes, compare rental prices in January 2021 to prices in January 2020. Make a table that shows the 10 ZIP codes (along with the borough and neighborhood) with largest drop in price from January 2020 to 2021. Comment.

```{r price_drop}
jan20 <- zillow_df %>%
  filter(date == ymd("2020-01-31")) %>%
  select(zip_code, zori_2020 = zori)

jan21 <- zillow_df %>%
  filter(date == ymd("2021-01-31")) %>%
  select(zip_code, zori_2021 = zori)

loc_lookup <- zillow_df %>%
  select(
    zip_code,
    county       = any_of("county"),
    neighborhood = any_of("neighborhood")
  ) %>%
  distinct() %>%
  mutate(
    borough = dplyr::recode(
      county,
      "Bronx"    = "Bronx",
      "Kings"    = "Brooklyn",
      "New York" = "Manhattan",
      "Queens"   = "Queens",
      "Richmond" = "Staten Island",
      .default   = NA_character_
    )
  )

largest10_drop <- jan20 %>%
  inner_join(jan21, by = "zip_code") %>%
  mutate(
    change     = zori_2021 - zori_2020,
    pct_change = 100 * change / zori_2020
  ) %>%
  left_join(loc_lookup, by = "zip_code") %>%
  arrange(change) %>%                 
  slice_head(n = 10) %>%
  select(zip_code, borough, neighborhood,
         zori_2020, zori_2021, change, pct_change)

knitr::kable(largest10_drop,
             digits = c(0, NA, NA, 1, 1, 1, 1),
             align  = "l",
             caption = "Largest ZORI drops (Jan 2020 → Jan 2021)")
```
The top 10 largest drops in price by ZIP code are all located in Manhattan and mainly correspond with the large exodus of individuals during the early stages of the pandemic.